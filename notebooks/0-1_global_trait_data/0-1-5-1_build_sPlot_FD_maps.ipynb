{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1.5.1: Build sPlot functional diversity maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from box import ConfigBox\n",
    "\n",
    "from src.conf.conf import get_config\n",
    "from src.conf.environment import detect_system, log\n",
    "from src.utils.dask_utils import close_dask, init_dask\n",
    "from src.utils.df_utils import rasterize_points, reproject_geo_to_xy\n",
    "from src.utils.raster_utils import xr_to_raster\n",
    "from src.utils.trait_utils import clean_species_name, filter_pft\n",
    "\n",
    "cfg = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-22 15:11:15 CEST - src.conf.environment - INFO - Starting sPlot map generation...\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:15 CEST - src.conf.environment - INFO - Detected system: nemo2\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:15 CEST - src.conf.environment - INFO - === STAGE 1: Initial Setup ===\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:15 CEST - src.conf.environment - INFO - Using sPlot data from: data/interim/splot/extracted\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:15 CEST - src.conf.environment - INFO - === STAGE 3: Dask Initialization ===\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:15 CEST - src.conf.environment - INFO - Initializing Dask client with parameters: {'n_workers': 40, 'threads_per_worker': 5, 'memory_limit': '40GB'}\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:18 CEST - src.conf.environment - INFO - Dask dashboard URL: http://127.0.0.1:39143/status\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Starting sPlot map generation...\")\n",
    "sys_cfg = cfg[detect_system()][cfg.model_res][\"build_splot_maps\"]\n",
    "\n",
    "# Setup ################\n",
    "log.info(\"=== STAGE 1: Initial Setup ===\")\n",
    "splot_dir = Path(cfg.interim_dir, cfg.splot.interim.dir) / cfg.splot.interim.extracted\n",
    "log.info(\"Using sPlot data from: %s\", splot_dir)\n",
    "\n",
    "\n",
    "# Check if we need to compute functional diversity metrics\n",
    "trait_stats = cfg.datasets.Y.trait_stats\n",
    "fd_metrics = [\"f_ric\", \"f_eve\", \"f_div\", \"f_red\", \"sp_ric\", \"f_ric_ses\"]\n",
    "use_fd_approach = any(stat in fd_metrics for stat in trait_stats)\n",
    "\n",
    "\n",
    "def _repartition_if_set(df: dd.DataFrame, npartitions: int | None) -> dd.DataFrame:\n",
    "    return df.repartition(npartitions=npartitions) if npartitions is not None else df\n",
    "\n",
    "\n",
    "# create dict of dask kws, but only if they are not None\n",
    "dask_kws = {k: v for k, v in sys_cfg.dask.items() if v is not None}\n",
    "log.info(\"=== STAGE 3: Dask Initialization ===\")\n",
    "log.info(\"Initializing Dask client with parameters: %s\", dask_kws)\n",
    "client, _ = init_dask(dashboard_address=cfg.dask_dashboard, **dask_kws)\n",
    "# /Setup ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-22 15:11:18 CEST - src.conf.environment - INFO - Discovering PCA component columns for functional diversity metrics...\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:18 CEST - src.conf.environment - INFO - Found 4 PCA columns: PC1, PC2, PC3, PC4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if use_fd_approach:\n",
    "    # For functional diversity approach, we need to discover all PCA columns\n",
    "    # First load the columns metadata to identify PCA columns\n",
    "    log.info(\"Discovering PCA component columns for functional diversity metrics...\")\n",
    "    trait_file_path = (\n",
    "        Path(cfg.interim_dir, cfg.trydb.interim.dir) / cfg.trydb.interim.filtered\n",
    "    )\n",
    "    trait_meta = dd.read_parquet(trait_file_path, calculate_divisions=False)\n",
    "    pca_cols = [col for col in trait_meta.columns if col.startswith(\"PC\")]\n",
    "\n",
    "    log.info(\"Found %d PCA columns: %s\", len(pca_cols), \", \".join(pca_cols))\n",
    "\n",
    "    needed_columns = [\"speciesname\"] + pca_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sPlot header data. This contains plot information and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PlotObservationID', 'Dataset', 'GIVD_NU', 'RESURVEY', 'RS_PLOT',\n",
       "       'RS_OBSERV', 'Nested_in', 'Longitude', 'Latitude',\n",
       "       'Location_uncertainty', 'Location_origin', 'Locality', 'Country',\n",
       "       'Subregion', 'Continent', 'Date', 'Releve_area', 'Cover_scale',\n",
       "       'Plants_recorded', 'Lichens_identified', 'Mosses_identified', 'FL_full',\n",
       "       'FL_name', 'FL_code', 'FL_first', 'FL_second', 'FL_third', 'EUNIS',\n",
       "       'EUNIS_old', 'EUNIS_coal', 'EUNIS_first', 'EUNIS_second', 'EUNIS_third',\n",
       "       'Naturalness', 'Grassland', 'Shrubland', 'Forest', 'Wetland',\n",
       "       'Sparse_vegetation', 'Cover_total', 'Cover_cryptogams', 'Cover_forbs',\n",
       "       'Cover_bare_soil', 'Cover_bare_rock', 'Cover_open_water',\n",
       "       'Cover_layer_litter', 'Cover_layer_algae', 'Cover_layer_lichen',\n",
       "       'Cover_layer_moss', 'Cover_layer_herb', 'Cover_layer_shrub',\n",
       "       'Cover_layer_tree', 'Max_height_cryptogams_mm',\n",
       "       'Avg_height_low_herbs_cm', 'Avg_height_high_herbs_cm',\n",
       "       'Max_height_herbs_cm', 'Height_low_shrubs_m', 'Height_high_shrubs_m',\n",
       "       'Height_low_trees_m', 'Height_high_trees_m', 'Altitude', 'Aspect',\n",
       "       'Slope', 'LOC_METHOD', 'MANIPULATE', 'MANIPTYP',\n",
       "       'Original_field_number', 'Original_number_database', 'Original_table',\n",
       "       'Original_number_table', 'Biblioreference', 'Author', 'Project',\n",
       "       'Publication_date', 'Remarks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.read_parquet(splot_dir / \"header.parquet\").columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-22 15:11:18 CEST - src.conf.environment - INFO - Loading sPlot header data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-22 15:11:18 CEST - src.conf.environment - INFO - Header data loaded and processed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def _filter_certain_plots(df: pd.DataFrame, givd_nu: str) -> pd.DataFrame:\n",
    "    \"\"\"Filter out certain plots.\"\"\"\n",
    "    return df[df[\"GIVD_NU\"] != givd_nu]\n",
    "\n",
    "\n",
    "log.info(\"Loading sPlot header data...\")\n",
    "header = (\n",
    "    dd.read_parquet(\n",
    "        splot_dir / \"header.parquet\",\n",
    "        columns=[\"PlotObservationID\", \"Longitude\", \"Latitude\", \"GIVD_NU\"],\n",
    "    )\n",
    "    .astype(\n",
    "        {\n",
    "            \"PlotObservationID\": \"uint32[pyarrow]\",\n",
    "            \"GIVD_NU\": \"category\",\n",
    "        }\n",
    "    )\n",
    "    .pipe(_repartition_if_set, sys_cfg.npartitions)\n",
    "    .pipe(_filter_certain_plots, \"00-RU-008\")\n",
    "    .drop(columns=[\"GIVD_NU\"])\n",
    "    .astype({\"Longitude\": np.float64, \"Latitude\": np.float64})\n",
    "    .set_index(\"PlotObservationID\")\n",
    "    .map_partitions(reproject_geo_to_xy, to_crs=cfg.crs, x=\"Longitude\", y=\"Latitude\")\n",
    "    .drop(columns=[\"Longitude\", \"Latitude\"])\n",
    ")\n",
    "log.info(\"Header data loaded and processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PlotObservationID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.443369e+07</td>\n",
       "      <td>6.833109e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.443358e+07</td>\n",
       "      <td>6.833128e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.443389e+07</td>\n",
       "      <td>6.833086e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.443415e+07</td>\n",
       "      <td>6.833099e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.443393e+07</td>\n",
       "      <td>6.833053e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              x             y\n",
       "PlotObservationID                            \n",
       "1                 -1.443369e+07  6.833109e+06\n",
       "2                 -1.443358e+07  6.833128e+06\n",
       "3                 -1.443389e+07  6.833086e+06\n",
       "4                 -1.443415e+07  6.833099e+06\n",
       "5                 -1.443393e+07  6.833053e+06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trait data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-22 15:11:26 CEST - src.conf.environment - INFO - Loading trait data for columns: speciesname, PC1, PC2, PC3, PC4\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:26 CEST - src.conf.environment - INFO - Trait data loaded and indexed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Loading trait data for columns: %s\", \", \".join(needed_columns))\n",
    "\n",
    "# Load pre-cleaned and filtered TRY traits and set species as index\n",
    "traits = (\n",
    "    dd.read_parquet(\n",
    "        Path(cfg.interim_dir, cfg.trydb.interim.dir) / cfg.trydb.interim.filtered,\n",
    "        columns=needed_columns,\n",
    "    )\n",
    "    .pipe(_repartition_if_set, sys_cfg.npartitions)\n",
    "    .set_index(\"speciesname\")\n",
    ")\n",
    "log.info(\"Trait data loaded and indexed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speciesname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abarema adenophora</th>\n",
       "      <td>5.840701</td>\n",
       "      <td>0.398256</td>\n",
       "      <td>0.723679</td>\n",
       "      <td>4.098356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarema adenophorum</th>\n",
       "      <td>2.897819</td>\n",
       "      <td>0.518998</td>\n",
       "      <td>-0.611865</td>\n",
       "      <td>2.608451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarema alexandri</th>\n",
       "      <td>2.395000</td>\n",
       "      <td>-0.759245</td>\n",
       "      <td>-1.042815</td>\n",
       "      <td>2.819884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarema barbouriana</th>\n",
       "      <td>1.696300</td>\n",
       "      <td>-1.297582</td>\n",
       "      <td>-1.096845</td>\n",
       "      <td>2.978906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarema cochleata</th>\n",
       "      <td>2.251713</td>\n",
       "      <td>-0.984658</td>\n",
       "      <td>-1.032982</td>\n",
       "      <td>2.988290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          PC1       PC2       PC3       PC4\n",
       "speciesname                                                \n",
       "abarema adenophora   5.840701  0.398256  0.723679  4.098356\n",
       "abarema adenophorum  2.897819  0.518998 -0.611865  2.608451\n",
       "abarema alexandri    2.395000 -0.759245 -1.042815  2.819884\n",
       "abarema barbouriana  1.696300 -1.297582 -1.096845  2.978906\n",
       "abarema cochleata    2.251713 -0.984658 -1.032982  2.988290"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-22 15:11:28 CEST - src.conf.environment - INFO - Loading and processing PFT data...\u001b[0m\n",
      "\u001b[94m2025-04-22 15:11:28 CEST - src.conf.environment - INFO - PFT data loaded and processed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load PFT data, filter by desired PFT, clean species names, and set them as index\n",
    "# for joining\n",
    "log.info(\"Loading and processing PFT data...\")\n",
    "pft_path = Path(cfg.raw_dir, cfg.trydb.raw.pfts)\n",
    "if pft_path.suffix == \".csv\":\n",
    "    pfts = dd.read_csv(Path(cfg.raw_dir, cfg.trydb.raw.pfts), encoding=\"latin-1\")\n",
    "elif pft_path.suffix == \".parquet\":\n",
    "    pfts = dd.read_parquet(Path(cfg.raw_dir, cfg.trydb.raw.pfts))\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported PFT file format: {pft_path.suffix}\")\n",
    "\n",
    "pfts = (\n",
    "    pfts.astype(\n",
    "        {\n",
    "            \"AccSpeciesName\": \"string[pyarrow]\",\n",
    "            \"pft\": \"category\",\n",
    "        }\n",
    "    )\n",
    "    .pipe(_repartition_if_set, sys_cfg.npartitions)\n",
    "    .pipe(filter_pft, cfg.PFT)\n",
    "    .drop(columns=[\"AccSpeciesID\"])\n",
    "    .dropna(subset=[\"AccSpeciesName\"])\n",
    "    .pipe(clean_species_name, \"AccSpeciesName\", \"speciesname\")\n",
    "    .drop(columns=[\"AccSpeciesName\"])\n",
    "    .drop_duplicates(subset=[\"speciesname\"])\n",
    "    .set_index(\"speciesname\")\n",
    ")\n",
    "log.info(\"PFT data loaded and processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 15:11:30,166 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 4d98352ee8ef0fab67fe833d5ec97679 initialized by task ('shuffle-transfer-4d98352ee8ef0fab67fe833d5ec97679', 9) executed on worker tcp://127.0.0.1:33405\n",
      "2025-04-22 15:11:34,893 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 4d98352ee8ef0fab67fe833d5ec97679 deactivated due to stimulus 'task-finished-1745327494.8914015'\n",
      "2025-04-22 15:12:25,664 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 2495dc5536bb522a8a4d48c893c63517 initialized by task ('shuffle-transfer-2495dc5536bb522a8a4d48c893c63517', 9) executed on worker tcp://127.0.0.1:38289\n",
      "2025-04-22 15:12:27,871 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 2495dc5536bb522a8a4d48c893c63517 deactivated due to stimulus 'task-finished-1745327547.8692358'\n",
      "2025-04-22 15:13:13,762 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 2495dc5536bb522a8a4d48c893c63517 initialized by task ('shuffle-transfer-2495dc5536bb522a8a4d48c893c63517', 51) executed on worker tcp://127.0.0.1:36453\n",
      "2025-04-22 15:13:17,728 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 2495dc5536bb522a8a4d48c893c63517 deactivated due to stimulus 'task-finished-1745327597.7268791'\n",
      "2025-04-22 15:13:19,826 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle bb726ac70ea7de56d7d2ccd9d2dbbbdb initialized by task ('shuffle-transfer-bb726ac70ea7de56d7d2ccd9d2dbbbdb', 6) executed on worker tcp://127.0.0.1:37953\n",
      "2025-04-22 15:13:21,551 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 7d98035ed295990d058f6525bd902640 initialized by task ('shuffle-transfer-7d98035ed295990d058f6525bd902640', 53) executed on worker tcp://127.0.0.1:46263\n",
      "2025-04-22 15:13:23,007 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle bb726ac70ea7de56d7d2ccd9d2dbbbdb deactivated due to stimulus 'task-finished-1745327602.9992802'\n",
      "2025-04-22 15:13:30,977 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 07cd8d76abe09a853e0cc819bad88b28 initialized by task ('shuffle-transfer-07cd8d76abe09a853e0cc819bad88b28', 59) executed on worker tcp://127.0.0.1:44823\n",
      "2025-04-22 15:13:35,887 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 7d98035ed295990d058f6525bd902640 deactivated due to stimulus 'task-finished-1745327615.8859682'\n",
      "2025-04-22 15:14:09,966 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 07cd8d76abe09a853e0cc819bad88b28 deactivated due to stimulus 'task-finished-1745327649.6515107'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speciesname</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa argyrolepis</th>\n",
       "      <td>Grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa calceata</th>\n",
       "      <td>Shrub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa colombiana</th>\n",
       "      <td>Grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa fiebrigii</th>\n",
       "      <td>Shrub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa hartwegii</th>\n",
       "      <td>Grass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pft\n",
       "speciesname          \n",
       "aa argyrolepis  Grass\n",
       "aa calceata     Shrub\n",
       "aa colombiana   Grass\n",
       "aa fiebrigii    Shrub\n",
       "aa hartwegii    Grass"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load vegetation data and merge with PFTs and trait data. We'll persist the dataframe since it will be used in later calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-22 15:11:35 CEST - src.conf.environment - INFO - Loading and processing sPlot vegetation data...\u001b[0m\n",
      "\u001b[94m2025-04-22 15:14:25 CEST - src.conf.environment - INFO - Data merging complete\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load sPlot vegetation records, clean species names, match with desired PFT, and\n",
    "# merge with trait data\n",
    "log.info(\"Loading and processing sPlot vegetation data...\")\n",
    "merged = (\n",
    "    dd.read_parquet(\n",
    "        splot_dir / \"vegetation.parquet\",\n",
    "        columns=[\n",
    "            \"PlotObservationID\",\n",
    "            \"Species\",\n",
    "            \"Rel_Abund_Plot\",\n",
    "        ],\n",
    "    )\n",
    "    .astype(\n",
    "        {\n",
    "            \"PlotObservationID\": \"uint32[pyarrow]\",\n",
    "            \"Species\": \"string[pyarrow]\",\n",
    "            \"Rel_Abund_Plot\": \"float64[pyarrow]\",\n",
    "        }\n",
    "    )\n",
    "    .pipe(_repartition_if_set, sys_cfg.npartitions)\n",
    "    .dropna(subset=[\"Species\"])\n",
    "    .pipe(clean_species_name, \"Species\", \"speciesname\")\n",
    "    .drop(columns=[\"Species\"])\n",
    "    .set_index(\"speciesname\")\n",
    "    .join(pfts, how=\"inner\")\n",
    "    .join(traits, how=\"inner\")\n",
    "    .reset_index()\n",
    "    .drop(columns=[\"pft\", \"speciesname\"])\n",
    "    .compute()\n",
    ")\n",
    "log.info(\"Data merging complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DF shape:  (40316038, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlotObservationID</th>\n",
       "      <th>Rel_Abund_Plot</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2552892</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>5.840701</td>\n",
       "      <td>0.398256</td>\n",
       "      <td>0.723679</td>\n",
       "      <td>4.098356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2555092</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>5.840701</td>\n",
       "      <td>0.398256</td>\n",
       "      <td>0.723679</td>\n",
       "      <td>4.098356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2555108</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>5.840701</td>\n",
       "      <td>0.398256</td>\n",
       "      <td>0.723679</td>\n",
       "      <td>4.098356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2552804</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>2.101126</td>\n",
       "      <td>-1.562004</td>\n",
       "      <td>-1.777728</td>\n",
       "      <td>1.707156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2553185</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>2.101126</td>\n",
       "      <td>-1.562004</td>\n",
       "      <td>-1.777728</td>\n",
       "      <td>1.707156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlotObservationID  Rel_Abund_Plot       PC1       PC2       PC3       PC4\n",
       "0            2552892        0.035714  5.840701  0.398256  0.723679  4.098356\n",
       "1            2555092        0.047619  5.840701  0.398256  0.723679  4.098356\n",
       "2            2555108        0.018868  5.840701  0.398256  0.723679  4.098356\n",
       "3            2552804        0.071429  2.101126 -1.562004 -1.777728  1.707156\n",
       "4            2553185        0.058824  2.101126 -1.562004 -1.777728  1.707156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Merged DF shape: \", merged.shape)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by vegetation plot and remove plots for which the TRY-matched observations don't cover at least 80% of the abundance and that have fewer than 3 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter groups based on abundance and observation count\n",
    "df_by_plots = merged.groupby(\"PlotObservationID\").filter(\n",
    "    lambda x: (x[\"Rel_Abund_Plot\"].sum() >= 0.8) and (len(x) >= 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DF shape: (40316038, 6)\n",
      "Filtered DF shape: (22701202, 6)\n",
      "Number of plots removed: 1251767\n",
      "Percentage of plots kept: 50.05 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Original DF shape:\", merged.shape)\n",
    "print(\"Filtered DF shape:\", df_by_plots.shape)\n",
    "print(\n",
    "    \"Number of plots removed:\",\n",
    "    merged[\"PlotObservationID\"].nunique() - df_by_plots[\"PlotObservationID\"].nunique(),\n",
    ")\n",
    "print(\n",
    "    \"Percentage of plots kept:\",\n",
    "    np.round(\n",
    "        (\n",
    "            df_by_plots[\"PlotObservationID\"].nunique()\n",
    "            / merged[\"PlotObservationID\"].nunique()\n",
    "            * 100\n",
    "        ),\n",
    "        2,\n",
    "    ),\n",
    "    \"%\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functional diversity equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fd_stats(\n",
    "    g: pd.DataFrame,\n",
    "    pca_cols: list,\n",
    "    stats: list[str],\n",
    "    include_ses: bool = False,\n",
    "    random_seed: int | None = None,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate all functional diversity stats per plot.\n",
    "\n",
    "    Args:\n",
    "        g: DataFrame group containing species observations for a single plot\n",
    "        pca_cols: List of column names for PCA components\n",
    "        include_ses: Whether to include standardized effect size for functional richness\n",
    "        random_seed: Random seed for SES calculations\n",
    "\n",
    "    Returns:\n",
    "        Series with functional diversity metrics\n",
    "    \"\"\"\n",
    "    # Check if we have enough data to calculate metrics\n",
    "    if g.empty or len(g) < 2:\n",
    "        result = pd.Series(\n",
    "            [np.nan] * len(stats),\n",
    "            index=stats,\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # Extract trait matrix and normalize abundances\n",
    "    trait_matrix = g[pca_cols].values\n",
    "\n",
    "    # Convert abundances to numpy array before normalization to avoid ArrowExtensionArray issues\n",
    "    abundances_np = g[\"Rel_Abund_Plot\"].to_numpy()\n",
    "    abundances_sum = abundances_np.sum()\n",
    "    normalized_abund = (\n",
    "        abundances_np / abundances_sum\n",
    "        if abundances_sum > 0\n",
    "        else np.ones_like(abundances_np) / len(abundances_np)\n",
    "    )\n",
    "\n",
    "    calculated_stats = {s: 0.0 for s in stats}\n",
    "    if \"sp_ric\" in stats:\n",
    "        # Calculate species richness (number of species in the plot)\n",
    "        sp_richness = len(g)\n",
    "        calculated_stats[\"sp_ric\"] = sp_richness\n",
    "    if \"f_ric\" in stats:\n",
    "        # Calculate functional richness\n",
    "        f_ric = _calculate_fric(trait_matrix, plot_id=g.name, S=len(g))\n",
    "        calculated_stats[\"f_ric\"] = f_ric\n",
    "    if \"f_eve\" in stats:\n",
    "        # Calculate functional evenness\n",
    "        f_eve = calculate_functional_evenness(trait_matrix, normalized_abund)\n",
    "        calculated_stats[\"f_eve\"] = f_eve\n",
    "    if \"f_div\" in stats:\n",
    "        # Calculate functional divergence\n",
    "        f_div = calculate_mean_pairwise_dissimilarity(trait_matrix, normalized_abund)\n",
    "        calculated_stats[\"f_div\"] = f_div\n",
    "    if \"f_red\" in stats:\n",
    "        # Calculate functional redundancy (1 - functional divergence)\n",
    "        f_red = 1 - f_div if not np.isnan(f_div) else np.nan\n",
    "        calculated_stats[\"f_red\"] = f_red\n",
    "\n",
    "    result = pd.Series(\n",
    "        calculated_stats,\n",
    "        index=stats,\n",
    "    )\n",
    "\n",
    "    # # Calculate standardized effect size for functional richness if requested\n",
    "    # if include_ses and not np.isnan(f_ric) and len(g) > len(pca_cols):\n",
    "    #     f_ric_ses = _calculate_ses_fric(trait_matrix, random_seed=random_seed)\n",
    "    #     result[\"cf_ric_ses\"] = f_ric_ses\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _calculate_fric(\n",
    "    trait_matrix: np.ndarray,\n",
    "    plot_id: int | str,\n",
    "    S: int,\n",
    "    n_permutations: int = 999,\n",
    "    random_seed: int | None = None,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate functional richness (FRic) for a given plot.\n",
    "\n",
    "    Args:\n",
    "        trait_matrix: Array of trait values for species in the plot\n",
    "        plot_id: ID of the plot\n",
    "        S: Number of species in the plot\n",
    "        n_permutations: Number of permutations for null distribution\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract trait data for species in this plot\n",
    "    n_dims = trait_matrix.shape[1]\n",
    "\n",
    "    # Skip if not enough species for convex hull\n",
    "    if S <= n_dims:\n",
    "        log.warning(\"Not enough species for convex hull for plot %s\", plot_id)\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate observed functional richness\n",
    "    try:\n",
    "        from scipy.spatial import ConvexHull\n",
    "\n",
    "        hull = ConvexHull(trait_matrix)\n",
    "        observed_fric = hull.volume\n",
    "    except Exception:\n",
    "        # Cannot compute hull\n",
    "        log.warning(\"Cannot compute hull for plot %s\", plot_id)\n",
    "        return np.nan\n",
    "\n",
    "    # Generate null distributions by randomizing trait values\n",
    "    null_fric_values = []\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "\n",
    "    for _ in range(n_permutations):\n",
    "        # Randomly shuffle each trait column independently\n",
    "        null_matrix = np.zeros_like(trait_matrix)\n",
    "        for j in range(n_dims):\n",
    "            null_matrix[:, j] = rng.choice(trait_matrix[:, j], size=S, replace=False)\n",
    "\n",
    "        try:\n",
    "            null_hull = ConvexHull(null_matrix)\n",
    "            null_fric = null_hull.volume\n",
    "            null_fric_values.append(null_fric)\n",
    "        except Exception:\n",
    "            null_fric_values.append(np.nan)\n",
    "\n",
    "    # Calculate standardized effect size\n",
    "    null_fric_values = np.array([v for v in null_fric_values if not np.isnan(v)])\n",
    "\n",
    "    if len(null_fric_values) > 0:\n",
    "        null_mean = np.mean(null_fric_values)\n",
    "        null_std = np.std(null_fric_values)\n",
    "        if null_std > 0:\n",
    "            ses = (observed_fric - null_mean) / null_std\n",
    "        else:\n",
    "            log.warning(\n",
    "                \"Standard deviation of null FRic values is zero for plot %s\", plot_id\n",
    "            )\n",
    "            ses = np.nan\n",
    "    else:\n",
    "        log.warning(\"No null FRic values for plot %s\", plot_id)\n",
    "        ses = np.nan\n",
    "\n",
    "    return ses\n",
    "\n",
    "\n",
    "def calculate_functional_evenness(\n",
    "    trait_matrix: np.ndarray, abundances: np.ndarray | None = None\n",
    ") -> float:\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "    import numpy as np\n",
    "\n",
    "    # Calculate pairwise distances between species in trait space\n",
    "    dist_matrix = squareform(pdist(trait_matrix, metric=\"euclidean\"))\n",
    "\n",
    "    # Get minimum spanning tree\n",
    "    mst = minimum_spanning_tree(dist_matrix).toarray()\n",
    "\n",
    "    # Get branch lengths from MST\n",
    "    branch_lengths = []\n",
    "    for i in range(len(trait_matrix)):\n",
    "        for j in range(i + 1, len(trait_matrix)):\n",
    "            if mst[i, j] > 0:\n",
    "                # Weight branch by species abundances if provided\n",
    "                weight = 1.0\n",
    "                if abundances is not None:\n",
    "                    weight = abundances[i] * abundances[j]\n",
    "                branch_lengths.append((mst[i, j], weight))\n",
    "\n",
    "    # Sort branch lengths\n",
    "    branch_lengths.sort()\n",
    "\n",
    "    # Number of species\n",
    "    S = len(trait_matrix)\n",
    "\n",
    "    # Sum of minimum weighted branch lengths\n",
    "    weighted_distances = [min(bl[0], 1 / (S - 1)) * bl[1] for bl in branch_lengths]\n",
    "\n",
    "    # Calculate evenness as deviation from regular spacing\n",
    "    PEW = np.sum(weighted_distances) / (S - 1)\n",
    "    FEve = (PEW - 1 / (S - 1)) / (1 - 1 / (S - 1))\n",
    "\n",
    "    return FEve\n",
    "\n",
    "\n",
    "def calculate_mean_pairwise_dissimilarity(\n",
    "    trait_matrix: np.ndarray, abundances: np.ndarray, metric: Any = \"euclidean\"\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean Pairwise Dissimilarity (MPD).\n",
    "    MPD = Rao / Simpson\n",
    "\n",
    "    Args:\n",
    "        trait_matrix: Matrix of species trait values (species × traits)\n",
    "        abundances: Abundance weights for each species\n",
    "        metric: Distance metric to use (default: \"euclidean\")\n",
    "\n",
    "    Returns:\n",
    "        Mean Pairwise Dissimilarity (MPD)\n",
    "    \"\"\"\n",
    "    rao = calculate_rao_quadratic_entropy(trait_matrix, abundances, metric)\n",
    "    simpson = calculate_simpson_diversity(abundances)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if simpson > 0:\n",
    "        return rao / simpson\n",
    "    else:\n",
    "        log.warning(\"Simpson index is zero, returning NaN\")\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def calculate_simpson_diversity(abundances: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Simpson diversity index.\n",
    "\n",
    "    Args:\n",
    "        abundances: Array of species abundances\n",
    "\n",
    "    Returns:\n",
    "        Simpson diversity (1 - sum of squared relative abundances)\n",
    "    \"\"\"\n",
    "    # Normalize abundances if they don't sum to 1\n",
    "    if not np.isclose(np.sum(abundances), 1.0):\n",
    "        rel_abundances = abundances / np.sum(abundances)\n",
    "    else:\n",
    "        rel_abundances = abundances.copy()\n",
    "\n",
    "    # Simpson index = 1 - sum(p_i^2)\n",
    "    simpson = 1 - np.sum(rel_abundances**2)\n",
    "\n",
    "    assert isinstance(simpson, float)\n",
    "    return simpson\n",
    "\n",
    "\n",
    "def calculate_rao_quadratic_entropy(\n",
    "    trait_matrix: np.ndarray, abundances: np.ndarray, metric: Any = \"euclidean\"\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate Rao's quadratic entropy.\n",
    "\n",
    "    Args:\n",
    "        trait_matrix: Matrix of species trait values (species × traits)\n",
    "        abundances: Abundance weights for each species\n",
    "        metric: Distance metric to use (default: \"euclidean\")\n",
    "\n",
    "    Returns:\n",
    "        Rao's quadratic entropy (abundance-weighted mean of trait distances)\n",
    "    \"\"\"\n",
    "    if len(trait_matrix) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "    # Normalize abundances\n",
    "    if not np.isclose(np.sum(abundances), 1.0):\n",
    "        rel_abundances = abundances / np.sum(abundances)\n",
    "    else:\n",
    "        rel_abundances = abundances.copy()\n",
    "\n",
    "    # Calculate distance matrix\n",
    "    dist_matrix = squareform(pdist(trait_matrix, metric=metric))\n",
    "\n",
    "    # Calculate Rao's quadratic entropy\n",
    "    rao_qe = 0\n",
    "    for i in range(len(rel_abundances)):\n",
    "        for j in range(len(rel_abundances)):\n",
    "            rao_qe += rel_abundances[i] * rel_abundances[j] * dist_matrix[i, j]\n",
    "\n",
    "    return rao_qe / 2  # Divide by 2 because we double-count each pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate plot-wise FD metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plots in df_by_plots: 1254124\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of plots in df_by_plots:\", df_by_plots.PlotObservationID.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_plots = df_by_plots.PlotObservationID.unique().to_numpy()\n",
    "np.random.seed(42)\n",
    "sample_plots = np.random.choice(sample_plots, size=10000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_plots_sample = df_by_plots.query(\"PlotObservationID in @sample_plots\").groupby(\n",
    "    \"PlotObservationID\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_stats = [\"f_ric\", \"f_eve\", \"f_div\", \"f_red\", \"sp_ric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m2025-04-22 17:14:00 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 3382\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:01 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 6456\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:09 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 40700\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:09 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 42661\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:12 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 51667\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:12 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 53745\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:16 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 68610\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:16 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 70140\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:16 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 73034\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:20 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 86136\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:20 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 86138\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:21 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 91997\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:24 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 112748\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:24 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 115541\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:30 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 133602\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:30 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 134420\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:31 CEST - src.conf.environment - WARNING - Cannot compute hull for plot 143280\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:37 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 157867\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:37 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 158893\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:38 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 161352\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:38 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 163561\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:39 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 166133\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:43 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 172098\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:44 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 173093\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:44 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 173204\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:45 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 174719\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:45 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 175211\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:45 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 175258\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:45 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 175349\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:45 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 175425\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:48 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 180881\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:48 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 181283\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:48 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 181302\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:49 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 181625\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:49 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 182540\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:49 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 188303\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:49 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 189538\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:49 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 189550\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:51 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 192362\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:51 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 193072\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:57 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 200267\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:58 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 202360\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:58 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 203336\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:58 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 203886\u001b[0m\n",
      "\u001b[93m2025-04-22 17:14:59 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 206360\u001b[0m\n",
      "\u001b[93m2025-04-22 17:15:00 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 209341\u001b[0m\n",
      "\u001b[93m2025-04-22 17:15:01 CEST - src.conf.environment - WARNING - Not enough species for convex hull for plot 210667\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "remove: path should be string, bytes or os.PathLike, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32mmessagestream.pyx:91\u001b[0m, in \u001b[0;36mscipy._lib.messagestream.MessageStream.close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: remove: path should be string, bytes or os.PathLike, not NoneType"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fd_df = df_by_plots_sample.apply(_fd_stats, pca_cols, stats=trait_stats, include_groups=False)\n",
    "\n",
    "fd_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
